)
decile_df %>%
group_by(decile) %>%
summarise(support = n(),
min_p = min(pdist),
proportion_remission = sum(remission==1) / n()) %>%
kable()
decile_plt <- decile_df %>%
group_by(decile) %>%
summarise(support = n(),
min_p = min(pdist),
proportion_remission = sum(remission==1) / n())
ggplot(decile_plt, aes(as.factor(decile), proportion_remission)) +
geom_bar(stat = 'identity') +
ylim(0, 1) +
geom_hline(yintercept=0.5, linetype="dashed", color = "red") +
theme_bw()
refit_data <- data.frame(outcome=y, X)
refit_data$outcome <- as.factor(refit_data$outcome)
# refit best learner model: Change this model based on SL learner performance but xgb can be a placeholder
xgb_mod <- boost_tree(mode = 'classification',
trees = 50,
learn_rate = 0.1,
tree_depth = 3) %>%
set_engine('xgboost')
rec <-
recipe(outcome ~ ., data = refit_data)
# set workflow
xgb_workflow <-
workflow() %>%
add_recipe(rec) %>%
add_model(xgb_mod)
shap_mod <- xgb_workflow %>%
fit(refit_data)
shap_data <- refit_data %>% dplyr::select(-outcome)
pred_fun <- function(object, newdata) {
predict(object, newdata, type = "prob") %>% dplyr::select(2)  # Probability of class "1"
}
set.seed(1)
shap_sample_index <- sample(x=1:nrow(shap_data), size = 50, replace = FALSE)
shap_explainer <- kernelshap(shap_mod,
X = shap_data,
bg_X = shap_data[shap_sample_index, ],
pred_fun = pred_fun,
verbose = FALSE)
sv <- shapviz(shap_explainer, X = shap_data)
beeswarm <- sv_importance(sv, kind = "bee")
beeswarm
#| warning: false
require(dplyr)
require(janitor)
require(fastDummies)
require(missMethods)
require(tidymodels)
require(recipeselectors)
require(parsnip)
require(yardstick)
require(vip)
require(ggplot2)
require(treeshap)
require(shapviz)
require(kernelshap)
require(dcurves)
require(knitr)
require(tableone)
require(SuperLearner)
require(caret)
require(MLmetrics)
require(splitstackshape)
require(RhpcBLASctl)
require(xgboost)
require(betacal)
require(mlbench)
require(givitiR)
require(ggpubr)
outcome <- 'madrs_response' # set to: madrs_response or madrs_remission
n_folds <- 10
filter_features <- TRUE
missingness_threshold <- 0.3
c_cutoff <- 0.9
cv_shuff <- FALSE # set to true later
# set paths
path_data <- '/Users/ls1002/Documents/Coding/ENGINE/data/'
path_code <- '/Users/ls1002/Documents/Coding/ENGINE/ENGINE_R/'
# load data
data <- read.csv(paste0(path_data, 'response_summary.csv'))
eeg <- read.csv(paste0(path_data, 'eeg_superfile_7.21.25.csv'))
#madrs_response is just responder_status
data$madrs_response <- data$responder_status
# remission
data$madrs_remission <- data$remitter_status
# set outcome
y <- data[[outcome]]
# drop follow-up variables
data_ss <- eeg
data_ss$record_id <- NULL
data_ss <- data_ss[, names(data_ss) %in% c(grep('_Beta_Abs_Power', names(data_ss), value = T))]
# reset outcome
data_clf <- data.frame(
outcome=y,
data_ss
)
X <- data_clf %>%
dplyr::select(-outcome)
y <- data_clf$outcome
if(filter_features){
# Filter near-zero variance variables
X <- X[, !names(X) %in% nzv(X, names = TRUE)]
# filter highly correlated variables
cm <- cor(X)
X <- X[, !names(X) %in% findCorrelation(cm, names =  TRUE, cutoff = c_cutoff)]
}
(num_cores = RhpcBLASctl::get_num_cores())
options(mc.cores = num_cores - 2)
getOption("mc.cores")
# ranger
mtry_seq <- c(2, floor(sqrt(ncol(X)) * c(0.5, 1)))
ranger_learners <- create.Learner("SL.ranger", tune = list(mtry = mtry_seq, num.trees=c(500, 1000)), detailed_names = TRUE)
# glmnet/elastic net
enet_learners <- create.Learner("SL.glmnet", tune = list(alpha = seq(0, 1, length.out=4)), detailed_names = TRUE)
xgb_tune <- list(ntrees = c(50, 100),
max_depth = 1:3,
shrinkage = c(0.001, 0.01, 0.1))
xgb_learners <- create.Learner("SL.xgboost", tune = xgb_tune, detailed_names = TRUE, name_prefix = "xgb")
svm_tune <- list(cost = c(0.1, 1, 10),
gamma = c(0.001, 0.01, 0.1, 1),
kernel = 'radial')
svm_learners <- create.Learner("SL.svm", tune = svm_tune, detailed_names = TRUE, name_prefix = 'svm')
set.seed(1, "L'Ecuyer-CMRG")
cv_sl = CV.SuperLearner(Y = y, X = X, family = binomial(),
cvControl = list(V = n_folds, stratifyCV = TRUE, shuffle = cv_shuff),
parallel = "multicore",
method = "method.AUC",
SL.library = c("SL.mean",
enet_learners$names, "SL.glmnet",
ranger_learners$names, "SL.ranger",
xgb_learners$names, "SL.xgboost",
svm_learners$names, "SL.svm"))
summary(cv_sl)
review_weights = function(cv_sl) {
meta_weights = coef(cv_sl)
means = colMeans(meta_weights)
sds = apply(meta_weights, MARGIN = 2,  FUN = sd)
mins = apply(meta_weights, MARGIN = 2, FUN = min)
maxs = apply(meta_weights, MARGIN = 2, FUN = max)
# Combine the stats into a single matrix.
sl_stats = cbind("mean(weight)" = means, "sd" = sds, "min" = mins, "max" = maxs)
# Sort by decreasing mean weight.
sl_stats[order(sl_stats[, 1], decreasing = TRUE), ]
}
print(review_weights(cv_sl), digits = 3)
plot(cv_sl)
# save predicted probabilities for each model
sl_probs <- data.frame(cv_sl$library.predict)
sl_probs$SL_model <- cv_sl$SL.predict
sl_probs$outcome <- y
# Fit beta calibration model
calibration_model <- beta_calibration(
p = sl_probs$SL_model,
y = sl_probs$outcome,
parameters = "ab" # options "abm", "ab", "am" corresponding to 3, 2, or 1 shape parameter
)
calibrated_probs <- beta_predict(sl_probs$SL_model, calibration_model)
# check calibration with giviti
belt_uncal <- givitiCalibrationBelt(sl_probs$outcome, sl_probs$SL_model, devel = "external")
belt_cal <- givitiCalibrationBelt(sl_probs$outcome, calibrated_probs, devel = "external")
par(mfrow=c(1, 2))
plot(belt_uncal, main = 'Uncalibrated')
plot(belt_cal, main = 'Beta Calibration')
if(belt_uncal$statistic <= belt_cal$statistic){
print("Uncalibrated model GiViTI statistic value is as good or better than beta calibration")
print(sprintf("Beta calibration = %s; Uncalibrated = %s", belt_cal$statistic, belt_uncal$statistic))
# set final model
sl_probs$SL_model_final <- sl_probs$SL_model
}else{
print("Beta calibrated model GiViTI statistic value is better than uncalibrated")
print(sprintf("Beta calibration = %s; Uncalibrated = %s", belt_cal$statistic, belt_uncal$statistic))
# set final model
sl_probs$SL_model_final <- calibrated_probs
}
# identify factor levels to determine event_level = first or second
print(levels(as.factor(sl_probs$outcome))) # is "1" the first or second level?
roc_plot <- sl_probs %>%
mutate(outcome=as.factor(outcome)) %>%
roc_curve(outcome, SL_model_final, event_level = 'second') %>%
autoplot()
pr_plot <- sl_probs %>%
mutate(outcome=as.factor(outcome)) %>%
pr_curve(outcome, SL_model_final, event_level = 'second') %>%
autoplot()
ggarrange(roc_plot, pr_plot, ncol = 2, nrow = 1)
# AUC-ROC value
sl_probs %>%
mutate(outcome=as.factor(outcome)) %>%
yardstick::roc_auc(outcome, SL_model_final, event_level = 'second')
# AUC-PR value
sl_probs %>%
mutate(outcome=as.factor(outcome)) %>%
yardstick::pr_auc(outcome, SL_model_final, event_level = 'second')
dc_data <- dcurves::dca(outcome ~ SL_model_final, data = sl_probs)
dc_data
# calculate difference in model-based versus treat-all-based net benefit
dc_df <- data.frame(dc_data$dca)
dc_df_ta <- dc_df[dc_df$label=='Treat All', ]
dc_df_mod <- dc_df[dc_df$label=='SL_model_final', ]
dc_df_mod$net_benefit_gain <- dc_df_mod$net_benefit - dc_df_ta$net_benefit
# subset over "reasonable range" and region of imporovement
tmp <- dc_df_mod[dc_df_mod$threshold < 0.45 & dc_df_mod$net_benefit_gain > 0, ]
tmp$nnt_gain <- (1/tmp$net_benefit_gain)
tmp$log_nnt_gain <- log(tmp$nnt_gain)
p1 <- ggplot(tmp, aes(threshold, net_benefit_gain)) +
geom_point(col='lightblue', size = 2) +
geom_line() +
ylab("Net Benefit Gain") +
xlab("Threshold Probability") +
theme_bw()
p2 <- ggplot(tmp, aes(threshold, log_nnt_gain)) +
geom_point(col='lightblue', size = 2) +
geom_line() +
ylab("Log NNT Gain") +
xlab("Threshold Probability") +
theme_bw()
ggarrange(p1, p2, ncol=2, nrow=1)
# report gain in NNT quantiles
kable(quantile(tmp$nnt_gain), caption = "NNT Gain Quantiles")
pdist <- sl_probs$SL_model_final
decile_membership <- ntile(pdist, 9)
decile_df <- data.frame(
pdist=pdist,
remission=y,
decile=decile_membership
)
decile_df %>%
group_by(decile) %>%
summarise(support = n(),
min_p = min(pdist),
proportion_remission = sum(remission==1) / n()) %>%
kable()
decile_plt <- decile_df %>%
group_by(decile) %>%
summarise(support = n(),
min_p = min(pdist),
proportion_remission = sum(remission==1) / n())
ggplot(decile_plt, aes(as.factor(decile), proportion_remission)) +
geom_bar(stat = 'identity') +
ylim(0, 1) +
geom_hline(yintercept=0.5, linetype="dashed", color = "red") +
theme_bw()
refit_data <- data.frame(outcome=y, X)
refit_data$outcome <- as.factor(refit_data$outcome)
# refit best learner model: Change this model based on SL learner performance but xgb can be a placeholder
xgb_mod <- boost_tree(mode = 'classification',
trees = 50,
learn_rate = 0.1,
tree_depth = 3) %>%
set_engine('xgboost')
rec <-
recipe(outcome ~ ., data = refit_data)
# set workflow
xgb_workflow <-
workflow() %>%
add_recipe(rec) %>%
add_model(xgb_mod)
shap_mod <- xgb_workflow %>%
fit(refit_data)
shap_data <- refit_data %>% dplyr::select(-outcome)
pred_fun <- function(object, newdata) {
predict(object, newdata, type = "prob") %>% dplyr::select(2)  # Probability of class "1"
}
set.seed(1)
shap_sample_index <- sample(x=1:nrow(shap_data), size = 50, replace = FALSE)
shap_explainer <- kernelshap(shap_mod,
X = shap_data,
bg_X = shap_data[shap_sample_index, ],
pred_fun = pred_fun,
verbose = FALSE)
sv <- shapviz(shap_explainer, X = shap_data)
beeswarm <- sv_importance(sv, kind = "bee")
beeswarm
#| warning: false
require(dplyr)
require(janitor)
require(fastDummies)
require(missMethods)
require(tidymodels)
require(recipeselectors)
require(parsnip)
require(yardstick)
require(vip)
require(ggplot2)
require(treeshap)
require(shapviz)
require(kernelshap)
require(dcurves)
require(knitr)
require(tableone)
require(SuperLearner)
require(caret)
require(MLmetrics)
require(splitstackshape)
require(RhpcBLASctl)
require(xgboost)
require(betacal)
require(mlbench)
require(givitiR)
require(ggpubr)
outcome <- 'madrs_response' # set to: madrs_response or madrs_remission
n_folds <- 10
filter_features <- TRUE
missingness_threshold <- 0.3
c_cutoff <- 0.9
cv_shuff <- FALSE # set to true later
# set paths
path_data <- '/Users/ls1002/Documents/Coding/ENGINE/data/'
path_code <- '/Users/ls1002/Documents/Coding/ENGINE/ENGINE_R/'
# load data
data <- read.csv(paste0(path_data, 'response_summary.csv'))
eeg <- read.csv(paste0(path_data, 'eeg_superfile_7.21.25.csv'))
#madrs_response is just responder_status
data$madrs_response <- data$responder_status
# remission
data$madrs_remission <- data$remitter_status
# set outcome
y <- data[[outcome]]
# drop follow-up variables
data_ss <- eeg
data_ss$record_id <- NULL
data_ss <- data_ss[, names(data_ss) %in% c(grep('_Beta_Abs_Power', names(data_ss), value = T))]
# reset outcome
data_clf <- data.frame(
outcome=y,
data_ss
)
X <- data_clf %>%
dplyr::select(-outcome)
y <- data_clf$outcome
if(filter_features){
# Filter near-zero variance variables
X <- X[, !names(X) %in% nzv(X, names = TRUE)]
# filter highly correlated variables
cm <- cor(X)
X <- X[, !names(X) %in% findCorrelation(cm, names =  TRUE, cutoff = c_cutoff)]
}
(num_cores = RhpcBLASctl::get_num_cores())
options(mc.cores = num_cores - 2)
getOption("mc.cores")
# ranger
mtry_seq <- c(2, floor(sqrt(ncol(X)) * c(0.5, 1)))
ranger_learners <- create.Learner("SL.ranger", tune = list(mtry = mtry_seq, num.trees=c(500, 1000)), detailed_names = TRUE)
# glmnet/elastic net
enet_learners <- create.Learner("SL.glmnet", tune = list(alpha = seq(0, 1, length.out=4)), detailed_names = TRUE)
xgb_tune <- list(ntrees = c(50, 100),
max_depth = 1:3,
shrinkage = c(0.001, 0.01, 0.1))
xgb_learners <- create.Learner("SL.xgboost", tune = xgb_tune, detailed_names = TRUE, name_prefix = "xgb")
svm_tune <- list(cost = c(0.1, 1, 10),
gamma = c(0.001, 0.01, 0.1, 1),
kernel = 'radial')
svm_learners <- create.Learner("SL.svm", tune = svm_tune, detailed_names = TRUE, name_prefix = 'svm')
set.seed(1, "L'Ecuyer-CMRG")
cv_sl = CV.SuperLearner(Y = y, X = X, family = binomial(),
cvControl = list(V = n_folds, stratifyCV = TRUE, shuffle = cv_shuff),
parallel = "multicore",
method = "method.AUC",
SL.library = c("SL.mean",
enet_learners$names, "SL.glmnet",
ranger_learners$names, "SL.ranger",
xgb_learners$names, "SL.xgboost",
svm_learners$names, "SL.svm"))
View(data_ss)
View(data_ss)
summary(cv_sl)
review_weights = function(cv_sl) {
meta_weights = coef(cv_sl)
means = colMeans(meta_weights)
sds = apply(meta_weights, MARGIN = 2,  FUN = sd)
mins = apply(meta_weights, MARGIN = 2, FUN = min)
maxs = apply(meta_weights, MARGIN = 2, FUN = max)
# Combine the stats into a single matrix.
sl_stats = cbind("mean(weight)" = means, "sd" = sds, "min" = mins, "max" = maxs)
# Sort by decreasing mean weight.
sl_stats[order(sl_stats[, 1], decreasing = TRUE), ]
}
print(review_weights(cv_sl), digits = 3)
plot(cv_sl)
# save predicted probabilities for each model
sl_probs <- data.frame(cv_sl$library.predict)
sl_probs$SL_model <- cv_sl$SL.predict
sl_probs$outcome <- y
# Fit beta calibration model
calibration_model <- beta_calibration(
p = sl_probs$SL_model,
y = sl_probs$outcome,
parameters = "ab" # options "abm", "ab", "am" corresponding to 3, 2, or 1 shape parameter
)
calibrated_probs <- beta_predict(sl_probs$SL_model, calibration_model)
# check calibration with giviti
belt_uncal <- givitiCalibrationBelt(sl_probs$outcome, sl_probs$SL_model, devel = "external")
belt_cal <- givitiCalibrationBelt(sl_probs$outcome, calibrated_probs, devel = "external")
par(mfrow=c(1, 2))
plot(belt_uncal, main = 'Uncalibrated')
plot(belt_cal, main = 'Beta Calibration')
if(belt_uncal$statistic <= belt_cal$statistic){
print("Uncalibrated model GiViTI statistic value is as good or better than beta calibration")
print(sprintf("Beta calibration = %s; Uncalibrated = %s", belt_cal$statistic, belt_uncal$statistic))
# set final model
sl_probs$SL_model_final <- sl_probs$SL_model
}else{
print("Beta calibrated model GiViTI statistic value is better than uncalibrated")
print(sprintf("Beta calibration = %s; Uncalibrated = %s", belt_cal$statistic, belt_uncal$statistic))
# set final model
sl_probs$SL_model_final <- calibrated_probs
}
# identify factor levels to determine event_level = first or second
print(levels(as.factor(sl_probs$outcome))) # is "1" the first or second level?
roc_plot <- sl_probs %>%
mutate(outcome=as.factor(outcome)) %>%
roc_curve(outcome, SL_model_final, event_level = 'second') %>%
autoplot()
pr_plot <- sl_probs %>%
mutate(outcome=as.factor(outcome)) %>%
pr_curve(outcome, SL_model_final, event_level = 'second') %>%
autoplot()
ggarrange(roc_plot, pr_plot, ncol = 2, nrow = 1)
# AUC-ROC value
sl_probs %>%
mutate(outcome=as.factor(outcome)) %>%
yardstick::roc_auc(outcome, SL_model_final, event_level = 'second')
# AUC-PR value
sl_probs %>%
mutate(outcome=as.factor(outcome)) %>%
yardstick::pr_auc(outcome, SL_model_final, event_level = 'second')
dc_data <- dcurves::dca(outcome ~ SL_model_final, data = sl_probs)
dc_data
# calculate difference in model-based versus treat-all-based net benefit
dc_df <- data.frame(dc_data$dca)
dc_df_ta <- dc_df[dc_df$label=='Treat All', ]
dc_df_mod <- dc_df[dc_df$label=='SL_model_final', ]
dc_df_mod$net_benefit_gain <- dc_df_mod$net_benefit - dc_df_ta$net_benefit
# subset over "reasonable range" and region of imporovement
tmp <- dc_df_mod[dc_df_mod$threshold < 0.45 & dc_df_mod$net_benefit_gain > 0, ]
tmp$nnt_gain <- (1/tmp$net_benefit_gain)
tmp$log_nnt_gain <- log(tmp$nnt_gain)
p1 <- ggplot(tmp, aes(threshold, net_benefit_gain)) +
geom_point(col='lightblue', size = 2) +
geom_line() +
ylab("Net Benefit Gain") +
xlab("Threshold Probability") +
theme_bw()
p2 <- ggplot(tmp, aes(threshold, log_nnt_gain)) +
geom_point(col='lightblue', size = 2) +
geom_line() +
ylab("Log NNT Gain") +
xlab("Threshold Probability") +
theme_bw()
ggarrange(p1, p2, ncol=2, nrow=1)
# report gain in NNT quantiles
kable(quantile(tmp$nnt_gain), caption = "NNT Gain Quantiles")
pdist <- sl_probs$SL_model_final
decile_membership <- ntile(pdist, 9)
decile_df <- data.frame(
pdist=pdist,
remission=y,
decile=decile_membership
)
decile_df %>%
group_by(decile) %>%
summarise(support = n(),
min_p = min(pdist),
proportion_remission = sum(remission==1) / n()) %>%
kable()
decile_plt <- decile_df %>%
group_by(decile) %>%
summarise(support = n(),
min_p = min(pdist),
proportion_remission = sum(remission==1) / n())
ggplot(decile_plt, aes(as.factor(decile), proportion_remission)) +
geom_bar(stat = 'identity') +
ylim(0, 1) +
geom_hline(yintercept=0.5, linetype="dashed", color = "red") +
theme_bw()
refit_data <- data.frame(outcome=y, X)
refit_data$outcome <- as.factor(refit_data$outcome)
# refit best learner model: Change this model based on SL learner performance but xgb can be a placeholder
xgb_mod <- boost_tree(mode = 'classification',
trees = 50,
learn_rate = 0.1,
tree_depth = 3) %>%
set_engine('xgboost')
rec <-
recipe(outcome ~ ., data = refit_data)
# set workflow
xgb_workflow <-
workflow() %>%
add_recipe(rec) %>%
add_model(xgb_mod)
shap_mod <- xgb_workflow %>%
fit(refit_data)
shap_data <- refit_data %>% dplyr::select(-outcome)
pred_fun <- function(object, newdata) {
predict(object, newdata, type = "prob") %>% dplyr::select(2)  # Probability of class "1"
}
set.seed(1)
shap_sample_index <- sample(x=1:nrow(shap_data), size = 50, replace = FALSE)
shap_explainer <- kernelshap(shap_mod,
X = shap_data,
bg_X = shap_data[shap_sample_index, ],
pred_fun = pred_fun,
verbose = FALSE)
sv <- shapviz(shap_explainer, X = shap_data)
beeswarm <- sv_importance(sv, kind = "bee")
beeswarm
